import java.util.*;

/**
 * Michael Pflaging
 * 09/09/2021
 * Implement a A-B-1 neural network that uses gradient descent for training
 */
public class NeuralNetwork
{
   //Declaring instance variables- arrays for activations and weights
   //Amount of space is hardcoded in later

   //Activations
   private double[][] activations;

   //Weights
   private double[][][] weights;

   //Expected Outputs
   private Map<double[],double[]> expectedOutputs;
   //For running
   private double[] outputs;

   //Inputs, Hidden activations, Outputs, Layers, Learning Factor
   private int numInputs;
   private int numActivations;
   private int numOutputs;
   private int numLayers;
   private double λ;

   //Training arrays
   private double[] hj;
   private double[] Θj;
   private double[] Ωj;
   private double[] Ψj;
   private double[][][] pE_pWkj;
   private double[][][] deltaWeights;
   //Other training
   private double F0;
   private double Θ0;
   private double ω0;
   private double ψ0;
   private double T0;
   //For storing random ranges
   private double minRand;
   private double maxRand;

   //For the outputs - for training
   private double[] expectedOutputValues;

   //Choose to train or run the network by changing this variable
   //True makes the network train, false makes the network run
   public static final boolean TRAIN_OR_RUN = true;

   /**
    * Initialize the network
    * @param numInputs the number of inputs to the network
    * @param numActivations the number of activations per hidden layer
    * @param numOutputs the number of output activations
    * @param numLayers the number of layers in the network
    */
   public NeuralNetwork(int numInputs, int numActivations, int numOutputs, int numLayers, double λ)
   {
      //Network specifics
      this.numInputs = numInputs;
      this.numActivations = numActivations;
      this.numOutputs = numOutputs;
      this.numLayers = numLayers;
      this.λ = λ;

      //Make sure the array of activations is large enough to store all
      //activations / inputs
      if (numActivations > numInputs)
      {
         activations = new double[numLayers][numActivations];
      }
      else{
         activations = new double[numLayers][numInputs];
      }
      
      weights = new double[numLayers-1][numActivations][numActivations];
      expectedOutputs = new HashMap<double[], double[]>();

      //Training arrays
      hj = new double[numActivations];
      Θj = new double[numActivations];
      Ωj = new double[numActivations];
      Ψj = new double[numActivations];
      pE_pWkj = new double[numLayers-1][numActivations][numActivations];
      deltaWeights = new double[numLayers-1][numActivations][numActivations];
   }

   /**
    * Generate a random number from a given minimum value to a maximum value
    * @param min The minimum value of the randomly generated number
    * @param max The maximum value of the randomly generated number
    * @return a double that is greater than or equal to the min value, and less than the max.
    */
   private static double generateRandomNumber(double min, double max)
   {
      return Math.random() * (max - min) + min;
   }

   /**
    * Calculate and return the result of the sigmoid function 
    * @param input the value being plugged in to the sigmoid function
    * @return the value of of the sigmoid after x has been plugged in
    */
   private static double sigmoid(double input)
   {
      return 1.0 / (1.0 + java.lang.Math.exp(-input));
   }

   /**
    * Calculate and return the value of the derivative of the sigmoid function
    * @param input the value passed to the derivate function
    * @return the value of the deriv of the sigmoid using the value of the sigmoid
    */
   private static double sigmoidDeriv(double input)
   {
      return sigmoid(input) * (1 - sigmoid(input));
   }

   /**
    * Calculate and return the value of the error given a certain ouptut value and
    * expected value
    * @param output the output value being compared to the expected value
    * @param expected the expected output value of the neural net
    * @return the calculated error value
    */
   private static double calculateError(double output, double expected)
   {
      return (0.5 * ( (expected - output) * (expected - output) ) );
   }

   /**
    * Set the weights of the neural network to be random values that are between
    * the min and max specified. Used for training the network
    * @param net the instance of NeuralNetwork which will have its weights set
    * @param min the minimum value of the weights
    * @param max the maximum value of the weights
    */
   private static void setRandomWeights(NeuralNetwork net, double min, double max)
   {
      //Loop through each layer
      for (int n = 0; n < net.weights.length; n++)
      {
         //Loop through each activation's weights in each layer
         for (int k = 0; k < net.weights[n].length; k++)
         {
            //Loop through each weight for each activation
            for (int j = 0; j < net.weights[n][k].length; j++)
            {
               //Assign a random value within the specified range to this weight
               net.weights[n][k][j] = generateRandomNumber(min, max);
            } //for (int j = 0; j < net.weights[n][k]; j++)
         } //for (int k = 0; k < net.weights[n].length; j++)
      } //for (int n = 0; n < net.weights.length; n++)
   }

   /**
    * Create and return a new neural network that is set up for
    * and, or, or xor. Later will read values off of a control file
    * but for now is super hardcoded
    * @return a new neural network ready for one of the three problems
    */
   private static NeuralNetwork createNetwork()
   {
      //Eventually these values passed will not be hardcoded
      //A-B-C values, #layers (dont change), lambda
      NeuralNetwork net = new NeuralNetwork(2, 2, 1, 3, 0.1);

      //Randomize weights if training, don't if just running
      if (TRAIN_OR_RUN)
      {
         //Range for the weights would later be read off of a file
         setRandomWeights(net, 0.1, 1.5);

         //Store random ranges in the network so that they can be outputted
         net.minRand = 0.1;
         net.maxRand = 1.5;
      }
      else
      {
         //Value for weights would later be read off of a file
         net.weights[0][0][0] = -5.0;
         net.weights[0][0][1] = -8.0;
         net.weights[0][1][0] = -1.0;
         net.weights[0][1][1] = 2.0;
         net.weights[1][0][0] = -20.0;
         net.weights[1][1][0] = 10.0;
      }

      //Set up either AND, OR, or XOR - these set the expected outputs
      // setupAND(net);
      setupOR(net);
      // setupXOR(net);

      return net;
   }

   /**
    * Set up the expected outputs for AND
    * @param net the network whose expected outputs are being configured
    */
   private static void setupAND(NeuralNetwork net)
   {
      net.expectedOutputs.put(new double[]{0.0, 0.0}, new double[]{0.0});
      net.expectedOutputs.put(new double[]{0.0, 1.0}, new double[]{0.0});
      net.expectedOutputs.put(new double[]{1.0, 0.0}, new double[]{0.0});
      net.expectedOutputs.put(new double[]{1.0, 1.0}, new double[]{1.0});

      net.expectedOutputValues = new double[]{0.0, 0.0, 0.0, 1.0};
   }

   /**
    * Set up the expected outputs for OR
    * @param net the network whose expected outputs are being configured
    */
   private static void setupOR(NeuralNetwork net)
   {
      net.expectedOutputs.put(new double[]{0.0, 0.0}, new double[]{0.0});
      net.expectedOutputs.put(new double[]{0.0, 1.0}, new double[]{1.0});
      net.expectedOutputs.put(new double[]{1.0, 0.0}, new double[]{1.0});
      net.expectedOutputs.put(new double[]{1.0, 1.0}, new double[]{1.0});

      net.expectedOutputValues = new double[]{0.0, 1.0, 1.0, 1.0};
   }

   /**
    * Set up the expected outputs for XOR
    * @param net the network whose expected outputs are being configured
    */
   private static void setupXOR(NeuralNetwork net)
   {
      net.expectedOutputs.put(new double[]{0.0, 0.0}, new double[]{0.0});
      net.expectedOutputs.put(new double[]{0.0, 1.0}, new double[]{1.0});
      net.expectedOutputs.put(new double[]{1.0, 0.0}, new double[]{1.0});
      net.expectedOutputs.put(new double[]{1.0, 1.0}, new double[]{0.0});

      net.expectedOutputValues = new double[]{0.0, 1.0, 1.0, 0.0};
   }

   /**
    * Run the network
    * @param net the instance of NeuralNetwork that will be run
    * @param out boolean determining whether all info is printed
    * @param table boolean determining if truth table is printed
    * @return the total error of the network
    */
   private static double runNetwork(NeuralNetwork net, boolean out, boolean table)
   {
      double totalError = 0.0;
      boolean printCompleteOutput = out;
      boolean printTruthTable = table;

      //Iterate through the different test cases of different input activations
      for (double[] inputs : net.expectedOutputs.keySet())
      {
         //Assign the input activation values
         for (int k = 0; k < net.numInputs; k++)
         {
            net.activations[0][k] = inputs[k];
         } //for (int n = 0; n < net.numInputs; n++)

         //Iterate through the hidden layers -> start on 1st (not 0th) layer and end before
         //output layer
         for (int n = 1; n < net.numLayers-1; n++)
         {
            //Iterate through each neuron in the hidden activation layer
            for (int j = 0; j < net.numActivations; j++)
            {
               //Test for if on the first layer of hidden activations
               if (n == 1)
               {
                  //Make sure activation is cleared from previous run
                  net.activations[n][j] = 0;

                  //Loop through input activations
                  for (int k = 0; k < net.numInputs; k++)
                  {
                     //Sum the dot products into the value of the activation
                     net.activations[n][j] = net.activations[n][j] + net.activations[n-1][k] * net.weights[n-1][k][j];
                  } //for (int k = 0; k < net.numInputs; k++)

                  //Then do the sigmoid
                  net.activations[n][j] = sigmoid(net.activations[n][j]);
               }

               //If not on the first later then on a normal hidden layer
               //Loop through input activations

               //Make sure activation is cleared from previous run
               net.activations[n][j] = 0;
               for (int k = 0; k < net.numActivations; k++)
               {
                  //Sum the dot products into the value of the activation
                  net.activations[n][j] = net.activations[n][j] + net.activations[n-1][k] * net.weights[n-1][k][j];
               } //for (int k = 0; k < net.numInputs; k++)

               //Then do the sigmoid
               net.activations[n][j] = sigmoid(net.activations[n][j]);
            } //for (int j = 0; j < net.numActivations; j++)
         } //for (int n = 1; n < net.numLayers-1; n++)

         //Now calculate output(s)
         //Loop through number of outputs
         for (int i = 0; i < net.numOutputs; i++)
         {
            //Loop through input activations
            //Make sure output activation is cleared before calculating
            net.activations[net.numLayers-1][i] = 0;
            for (int j = 0; j < net.numActivations; j++)
            {
               //Sum the dot products into the value of the activation
               net.activations[net.numLayers-1][i] = net.activations[net.numLayers-1][i] + 
                                                      net.activations[net.numLayers-2][j] * net.weights[net.numLayers-2][j][i];
            } //for (int k = 0; k < net.numInputs; k++)

            //Then do the sigmoid
            net.activations[net.numLayers-1][i] = sigmoid(net.activations[net.numLayers-1][i]);
         }
         
         net.outputs = net.expectedOutputs.get(inputs);
         //Calculate error
         for (int i = 0; i < net.numOutputs; i++)
         {
            //Add error for this run to total error
            totalError += calculateError(net.activations[net.numLayers-1][i], net.outputs[i]);
         } //for (int i = 0; i < net.numOutputs; i++)

         if (printTruthTable)
         {
            System.out.println(net.activations[0][0] + " " + net.activations[0][1] + "\t"+ net.expectedOutputs.get(inputs)[0] + "\t" + net.activations[2][0]);
         }

         if (printCompleteOutput)
         {
            //Calculate Error and print out stuff
            System.out.println(" ");
            //First print out the inputs of the trial
            System.out.print("Inputs: [");
            for (int k = 0; k < net.numInputs; k++)
            {
               System.out.print(inputs[k] + ", ");
            } //for (int k = 0; k < net.numInputs; k++)
            System.out.print("]\t");

            //Then print the expected value(s)
            System.out.print("Outputs: [");
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(net.activations[net.numLayers-1][i] + ", ");
            } //for (int i = 0; i < net.numOutputs; i++)
            System.out.print("]\t");

            //Now print Error
            System.out.print("Error: [");
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(calculateError(net.activations[net.numLayers-1][i], net.outputs[i]) + ", ");
            } //for (int i = 0; i < net.numOutputs; i++)
            System.out.print("]");
         }

      } //for (double[] inputs : net.expectedOutputs.keySet())

      if (printCompleteOutput)
      {
         //Next line
         System.out.println("");
         //Print total error
         System.out.println("Total Error: " + totalError);
         //Add blank line
         System.out.println("");
      }

      //Return total error
      return totalError;
   }

   /**
    * Train the network by first setting the weights to random values within 
    * a certain range, then finishing actually coding it lol
    */
   private static void trainNetwork()
   {

      //Train the network, so...
      
      //Create a new network
      NeuralNetwork net = createNetwork();
      
      //End conditions
      double minError = 0.01;
      int cyclesMax = 10000;

      //Error calculated by running network - set to 1 now but just temporary until
      //network is run
      double Error = 1;
      //Number of cycles
      int cycles = 0;

      //Loop through training until a end condition is met
      while(cycles < cyclesMax && Error > minError)
      {
         Error = runNetwork(net, false, false);
         //Do gradient descent

         //Cycle what is expected
         net.T0 = net.expectedOutputValues[cycles % net.expectedOutputValues.length];

         //First do the calculations for output layer
         net.Θ0 = 0.0;
         for (int j = 0; j < net.numActivations; j++)
         {
            net.Θ0 += net.activations[net.numLayers-2][j] * net.weights[net.numLayers-2][j][0];
         }
         net.F0 = sigmoid(net.Θ0);
         net.ω0 = (net.T0 - net.F0);
         net.ψ0 = net.ω0 * sigmoidDeriv(net.Θ0);
         
         //Calculate partials and change in weights
         for (int j = 0; j < net.numActivations; j++)
         {
            net.pE_pWkj[net.numLayers-2][j][0] = -net.activations[net.numLayers-2][j] * net.ψ0;
            net.deltaWeights[net.numLayers-2][j][0] = -(net.λ * net.pE_pWkj[net.numLayers-2][j][0]);
         }

         //Start from 2nd to last layer - this is the one hidden activation layer
         //For now this basically reads n = 1; n> 0; n--

         //Calculating Θj, Ωj, Ψj
         for (int n = net.numLayers-2; n > 0; n--)
         {
            //For each hidden activation
            for (int j = 0; j < net.numInputs; j++)
            {
               //For each input activation
               for (int k = 0; k < net.numActivations; k++)
               {
                  net.Θj[j] += net.activations[n-1][k] * net.weights[n-1][k][j];
                  net.Ωj[j] = net.ψ0 * net.weights[n][j][0];
                  net.Ψj[j] = net.Ωj[j] * sigmoidDeriv(net.Θj[j]);
               } //for (int k = 0; k < net.numActivations; k++)
            } //for (int j = 0; j < net.numInputs; j++)
         } //for (int n = net.numLayers-1; n >= 0; n--)

         //Calculate partials and change in weights
         //For each hidden activation
         for (int j = 0; j < net.numInputs; j++)
         {
            //For each input activation
            for (int k = 0; k < net.numActivations; k++)
            {
               net.pE_pWkj[0][k][j] = -net.activations[0][k] * net.Ψj[j];
               net.deltaWeights[0][k][j] = -(net.λ * net.pE_pWkj[0][k][j]);
            } //for (int k = 0; k < net.numActivations; k++)
         } //for (int j = 0; j < net.numInputs; j++)

         //Adjust weights

         //Go through each hidden activation weight layer
         for (int n = 0; n < net.numLayers-2; n++)
         {
            //Go through each input activation
            for (int k = 0; k < net.numInputs; k++)
            {
               //Go through each hidden activation
               for (int j = 0; j < net.numActivations; j++)
               {
                  net.weights[n][k][j] += net.deltaWeights[n][k][j];
               } //for (int j = 0; j < net.numActivations; j++)
            } //for (int k = 0; k < net.numInputs; k++)
         } //for (int n = 0; n < net.numLayers-2; n++)

         //For the output activation weights
         for (int j = 0; j < net.numActivations; j++)
         {
            net.weights[net.numLayers-2][j][0] += net.deltaWeights[net.numLayers-2][j][0];
         }

         //Run network
         Error = runNetwork(net, false, false);
         //Increment # of cycles
         cycles++;
      } //while(cycles < cyclesMax && Error > minError)

      //Print why it stopped
      if (cycles >= cyclesMax)
      {
         System.out.println("Hit maximum number of loops.");
      }
      else
      {
         System.out.println("Error was smaller than minError.");
      }

      //Print config and rand range
      System.out.println("Config: " + net.numInputs + " " + net.numActivations + " " + net.numOutputs);
      System.out.println("Rand range: " + net.minRand + " - " + net.maxRand);

      //Print N max and lambda
      System.out.println("N max was: " + cyclesMax);
      System.out.println("λ was: " + net.λ);

      //Print Error then # of iteration
      System.out.println("Error was: " + Error);
      System.out.println("# of iterations: " + cycles);

      //Now print truth table
      System.out.println("Truth Table");
      net.runNetwork(net, false, true);

      //Print weights      
      for (int n = 0; n < net.numLayers-1; n++)
      {
         for (int k = 0; k < net.numInputs; k++)
         {
            for (int j = 0; j < net.numActivations; j++)
            {
               System.out.println("Weight w" + n + k + j + " = " + net.weights[n][k][j]);
            } //for (int j = 0; j < net.numActivations; j++)
         } //for (int k = 0; k < net.numInputs; k++)         
      } //for (int n = 0; n < net.numLayers-2; n++)
      
   }

   /**
    * Create and set up an instance of NeuralNetwork to be run or trained
    * @param args the arguments passed to (and ignored by) the main method
    */
   public static void main(String[] args)
   {

      //Either train or run the network based on the value of TRAIN_OR_RUN
      if (TRAIN_OR_RUN)
      {
         trainNetwork();
      }
      else
      {
         runNetwork(createNetwork(), true, false);
      }
   }
}