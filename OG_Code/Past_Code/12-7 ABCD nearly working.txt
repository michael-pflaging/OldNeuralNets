import java.io.FileInputStream;
import java.io.FileWriter;
import java.io.IOException;
import org.json.*;
import java.nio.file.Files;
import java.nio.charset.*;
import java.nio.file.Paths;
import java.util.*;

/**
 * Michael Pflaging
 * 09/09/2021
 * Implement a A-B-C-D neural network that uses gradient descent for training and implements backprop
 * It can be run off of a control file that is specified at runtime and saves 
 * weights to a file whose name is specified in the control file
 * 
 * To-do: Make control file changeable at runtime
 */
public class NeuralNetwork
{
   //Activations
   private double[][] activations;
   //Weights
   private double[][][] weights;
   //Inputs, Hidden activations, Outputs, Layers, Learning Factor
   private int numInputs;
   private int numHidden1;
   private int numHidden2;
   private int numOutputs;
   private int numLayers;
   private double λ;

   //Training arrays
   private double[] am;
   private double[] Θk;
   private double[] ak;
   private double[] Θj;
   private double[] aj;
   private double[] Ψj;
   private double[] ai;
   private double[] ψi;
   private double[] Ti;
   //For storing random ranges
   private double minRand;
   private double maxRand;
   //Training conditions
   private double minError;
   private int cyclesMax;
   private int saveFrequency;
   //For storing sum of single set errors
   private double singleSetError;

   //For the possible inputs and expected outputs
   private double[][] possibleInputValues;
   private double[][] expectedOutputValues;

   private String weightFileName;
   //True makes the network train, false makes the network run
   private boolean trainOrRun;

   /**
    * Initialize the network
    * @param numInputs the number of input activations
    * @param numHidden1 the number of hidden activations in the 2nd layer
    * @param numHidden2 the number of hidden activations in the 3rd layer
    * @param numOutputs the number of output activations
    * @param numLayers the number of layers
    * @param λ the learning factor
    * @param weightFileName the name of the weight file to save/load from
    * @param trainOrRun boolean whether training or running
    * @param cyclesMax the maximum number of cycles while training
    * @param minError the minimum error at which training stops
    * @param minRand the lower bound of the random weights
    * @param maxRand the upper bound of the random weights
    * @param saveFrequency how often weights are saved while training
    */
   public NeuralNetwork(int numInputs, int numHidden1, int numHidden2, int numOutputs, int numLayers, double λ, String weightFileName, 
                        boolean trainOrRun, int cyclesMax, double minError, double minRand, double maxRand, int saveFrequency)
   {
      //Network specifics
      this.numInputs = numInputs;
      this.numHidden1 = numHidden1;
      this.numHidden2 = numHidden2;
      this.numOutputs = numOutputs;
      this.numLayers = numLayers;
      this.λ = λ;
      this.weightFileName = weightFileName;
      this.trainOrRun = trainOrRun;
      this.cyclesMax = cyclesMax;
      this.minError = minError;
      this.minRand = minRand;
      this.maxRand = maxRand;
      this.saveFrequency = saveFrequency;
      singleSetError = 0.0;

      
      //Make sure the array of activations is large enough to store all activations/outputs
      if (numHidden1 > numInputs && numHidden1 > numOutputs && numHidden1 > numHidden2)
      {
         activations = new double[numLayers][numHidden1];
      } //if (numHidden1 > numInputs && numHidden1 > numOutputs && numHidden1 > numHidden2)
      else if (numHidden2 > numInputs && numHidden2 > numOutputs)
      {
         activations = new double[numLayers][numHidden2];
      } //else if (numHidden2 > numInputs && numHidden2 > numOutputs)
      else if (numInputs > numOutputs)
      {
         activations = new double[numLayers][numInputs];
      } //else if
      else
      {
         activations = new double[numLayers][numOutputs];
      } //else

      //Make sure to have enough room
      if (numHidden1 > numOutputs && numHidden1 > numHidden2)
      {
         weights = new double[numLayers-1][numHidden1][numHidden1];
      } //if (numHidden1 > numOutputs && numHidden1 > numHidden2)
      else if (numHidden2 > numOutputs)
      {
         weights = new double[numLayers-1][numHidden2][numHidden2];
      } //else if (numHidden2 > numOutputs)
      else
      {
         weights = new double[numLayers-1][numOutputs][numOutputs];
      } //else

      //Only allocate space if training
      if (trainOrRun)
      {
      //Training arrays- k's are numHidden1, j's are numHidden2, and i's are numOutputs
      am = new double[numInputs];
      ak = new double[numHidden1];
      Θk = new double[numHidden1];
      aj = new double[numHidden2];
      Θj = new double[numHidden2];
      Ψj = new double[numHidden2];
      ai = new double[numOutputs];
      ψi = new double[numOutputs];
      Ti = new double[numOutputs];
      } //if (trainOrRun)
   } //public NeuralNetwork( lots of params )

   /**
    * Generate a random number from a given minimum value to a maximum value
    * @param min The minimum value of the randomly generated number
    * @param max The maximum value of the randomly generated number
    * @return a double that is greater than or equal to the min value, and less than the max.
    */
   private static double generateRandomNumber(double min, double max)
   {
      return Math.random() * (max - min) + min;
   } //private static double generateRandomNumber(double min, double max)

   /**
    * Calculate and return the result of the sigmoid function 
    * @param input the value being plugged in to the sigmoid function
    * @return the value of of the sigmoid after x has been plugged in
    */
   private static double sigmoid(double input)
   {
      return 1.0 / (1.0 + java.lang.Math.exp(-input));
   } //private static double sigmoid(double input)

   /**
    * Calculate and return the value of the derivative of the sigmoid function
    * @param input the value passed to the derivate function
    * @return the value of the deriv of the sigmoid using the value of the sigmoid
    */
   private static double sigmoidDeriv(double input)
   {
      return sigmoid(input) * (1.0 - sigmoid(input));
   } //private static double sigmoidDeriv(double input)

   /**
    * Calculate and return the value of the error given a certain ouptut value and
    * expected value
    * @param output the output value being compared to the expected value
    * @param expected the expected output value of the neural net
    * @return the calculated error value
    */
   private static double calculateError(double output, double expected)
   {
      return (0.5 * ( (expected - output) * (expected - output) ) );
   } //private static double calculateError(double output, double expected)

   /**
    * Set the weights of the neural network to be random values that are between
    * the min and max specified. Used for training the network. Technically this is
    * not the most efficient since every space in the weight array is filled regardless
    * of if it is needed
    * @param net the instance of NeuralNetwork which will have its weights set
    * @param min the minimum value of the weights
    * @param max the maximum value of the weights
    */
   private static void setRandomWeights(NeuralNetwork net, double min, double max)
   {
      //Loop through each layer
      for (int n = 0; n < net.weights.length; n++)
      {
         //Loop through each activation's weights in each layer
         for (int k = 0; k < net.weights[n].length; k++)
         {
            //Loop through each weight for each activation
            for (int j = 0; j < net.weights[n][k].length; j++)
            {
               //Assign a random value within the specified range to this weight
               net.weights[n][k][j] = generateRandomNumber(min, max);
            } //for (int j = 0; j < net.weights[n][k]; j++)
         } //for (int k = 0; k < net.weights[n].length; j++)
      } //for (int n = 0; n < net.weights.length; n++)
   } //private static void setRandomWeights(NeuralNetwork net, double min, double max)

   /**
    * Set up the expected outputs for AND, works for 2-B-1 network
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupAND(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0}, {0.0, 1.0}, {1.0, 0.0}, {1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0}, {0.0}, {0.0}, {1.0}};
   } //private static void setupAND(NeuralNetwork net)

   /**
    * Set up the expected outputs for OR, works for 2-B-1 network
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupOR(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0}, {0.0, 1.0}, {1.0, 0.0}, {1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0}, {1.0}, {1.0}, {1.0}};
   } //private static void setupOR(NeuralNetwork net)

   /**
    * Set up the expected outputs for XOR, works for 2-B-1 network
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupXOR(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0}, {0.0, 1.0}, {1.0, 0.0}, {1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0}, {1.0}, {1.0}, {0.0}};
   } //private static void setupXOR(NeuralNetwork net)

   /**
    * Set up the expected outputs for AND, OR, and XOR, works for 2-B-3 network
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupAndOrXor(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0}, {0.0, 1.0}, {1.0, 0.0}, {1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0, 0.0, 0.0}, {0.0, 1.0, 1.0}, {0.0, 1.0, 1.0}, {1.0, 1.0, 0.0}};
   } //private static void setupAndOrXor(NeuralNetwork net)

   /**
    * Set up more complex tester for a 3-B-4 network
    * Outputs are: XOR first two, AND of XOR function of first two with 3rd input,
    * OR of XOR function of first two with 3rd input, XOR of XOR function of first two with 3rd input
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupABCTester1(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0, 0.0}, {0.0, 0.0, 1.0}, {0.0, 1.0, 0.0}, {1.0, 0.0, 0.0},
                                                {0.0, 1.0, 1.0}, {1.0, 1.0, 0.0}, {1.0, 0.0, 1.0}, {1.0, 1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0, 0.0, 0.0, 0.0}, {0.0, 0.0, 1.0, 1.0}, {1.0, 0.0, 1.0, 1.0}, {1.0, 0.0, 1.0, 1.0},
                                                {1.0, 1.0, 1.0, 0.0}, {0.0, 0.0, 0.0, 0.0}, {1.0, 1.0, 1.0, 0.0}, {0.0, 0.0, 1.0, 1.0}};                           
   } //private static void setupABCTester1(NeuralNetwork net)

   /**
    * Set up another complex tester, this time for a 4-B-3 network
    * Outputs are: XOR first two, OR of 3 and 4, AND of XOR and OR
    * @param net the network whose inputs and outputs are being configured
    */
   private static void setupABCTester2(NeuralNetwork net)
   {
      net.possibleInputValues = new double[][]{{0.0, 0.0, 0.0, 0.0}, {0.0, 0.0, 0.0, 1.0}, {0.0, 0.0, 1.0, 0.0}, {0.0, 1.0, 0.0, 0.0},
                                                {1.0, 0.0, 0.0, 0.0}, {0.0, 0.0, 1.0, 1.0}, {0.0, 1.0, 0.0, 1.0}, {1.0, 0.0, 0.0, 1.0},
                                                {0.0, 1.0, 1.0, 0.0}, {1.0, 0.0, 1.0, 0.0}, {1.0, 1.0, 0.0, 0.0}, {0.0, 1.0, 1.0, 1.0},
                                                {1.0, 0.0, 1.0, 1.0}, {1.0, 1.0, 0.0, 1.0}, {1.0, 1.0, 1.0, 0.0}, {1.0, 1.0, 1.0, 1.0}};
      net.expectedOutputValues = new double[][]{{0.0, 0.0, 0.0}, {0.0, 1.0, 0.0}, {0.0, 1.0, 0.0}, {1.0, 0.0, 0.0},
                                                {1.0, 0.0, 0.0}, {0.0, 1.0, 0.0}, {1.0, 1.0, 1.0}, {1.0, 1.0, 1.0},
                                                {1.0, 1.0, 1.0}, {1.0, 1.0, 1.0}, {0.0, 0.0, 0.0}, {1.0, 1.0, 1.0},
                                                {1.0, 1.0, 1.0}, {0.0, 1.0, 0.0}, {0.0, 1.0, 0.0}, {0.0, 1.0, 0.0}};
   } //private static void setupABCTester2(NeuralNetwork net)

   /**
    * Write the contents of the network to a json file using JSON.simple
    * @param net the neural network whose information is being outputted to a file
    * @param fileName the name of the file being saved (.json extension is added to the name automatically)
    */
   private static void saveWeights(NeuralNetwork net, String fileName)
   {
      //Store weights
      JSONArray networkWeights = new JSONArray(net.weights); 

      try (FileWriter file = new FileWriter(fileName + ".json"))
      {
         //Write to file, value inside the toString is the spaces of indentation
         file.write(networkWeights.toString(3));
         
      } //try
      catch (IOException e) 
      {
         e.printStackTrace();
      } //catch (IOException ex) 
   } //private static void writeToJsonFile()

   /**
    * Load the weights from saved file (weights array MUST be right size before calling this)
    * @param fileName the weights file
    * @param net the network whose weights are being set from the file
    */
   private static void loadWeights(String fileName, NeuralNetwork net)
   {
      String content = "";
      try 
      {
         content = Files.readString(Paths.get(fileName + ".json"), StandardCharsets.US_ASCII);

      } //try
      catch (IOException e) 
      {
         e.printStackTrace();
      } //catch (IOException e) 

      //JSON tokener object to parse read file
      JSONTokener jsonTokener = new JSONTokener(content);
      
      //Read the weights (only object)
      JSONArray savedWeights = (JSONArray)jsonTokener.nextValue();

      //Loop through each layer
      for (int n = 0; n < net.weights.length; n++)
      {
         //Loop through each activation's weights in each layer
         for (int k = 0; k < net.weights[n].length; k++)
         {
            //Loop through each weight for each activation
            for (int j = 0; j < net.weights[n][k].length; j++)
            {
               //Get the weight value
               net.weights[n][k][j] = savedWeights.getJSONArray(n).getJSONArray(k).getDouble(j);
            } //for (int j = 0; j < net.weights[n][k]; j++)
         } //for (int k = 0; k < net.weights[n].length; j++)
      } //for (int n = 0; n < net.weights.length; n++)
   } //private static void loadWeights(String fileName, NeuralNetwork net)

   /**
    * Parse a control file and create a new NeuralNetwork according to the specifications
    * @return a neural network
    */
   private static NeuralNetwork loadFromControl(String fileName) throws IOException
   {
      //C for the content of the control file
      String[] c = Files.readString(Paths.get(fileName + ".txt")).split(", ");
      //This involves a lot of casting to the right type, if control file is messed up then errors galore
      return createNetwork(Integer.parseInt(c[0]), Integer.parseInt(c[1]), Integer.parseInt(c[2]), Integer.parseInt(c[3]), 
                           Integer.parseInt(c[4]), Double.parseDouble(c[5]), c[6], Boolean.parseBoolean(c[7]), Integer.parseInt(c[8]), 
                           Double.parseDouble(c[9]), Double.parseDouble(c[10]), Double.parseDouble(c[11]), Boolean.parseBoolean(c[12]), 
                           Integer.parseInt(c[13]));
   } //private static NeuralNetwork loadFromControl(String fileName) throws IOException

   /**
    * Run the network
    * @param net the instance of NeuralNetwork that will be run
    * @param printComplete boolean determining whether all info is printed
    * @param printTable boolean determining if truth table is printed
    * @return the total error of the network
    */
   private static double runNetwork(NeuralNetwork net, boolean printComplete, boolean printTable)
   {
      double totalError = 0.0;

      //Iterate through the different test cases of different input activations
      for (int a = 0; a < net.possibleInputValues.length; a++)
      {
         //Assign the input activation values
         for (int m = 0; m < net.numInputs; m++)
         {
            net.activations[0][m] = net.possibleInputValues[a][m];
         } //for (int m = 0; m < net.numInputs; m++)

         /*
         * Evaluate the first hidden layer (n = 1)
         * Iterate through each neuron in the hidden activation layer
         */
         for (int k = 0; k < net.numHidden1; k++)
         {
            //Declare Θk
            double Θk = 0.0;

            //Loop through input activations
            for (int m = 0; m < net.numInputs; m++)
            {
               //Sum the dot products into the value of the activation
               Θk += net.activations[0][m] * net.weights[0][m][k];
            } //for (int m = 0; m < net.numInputs; m++)

            //Then do the sigmoid
            net.activations[1][k] = sigmoid(Θk);
         } //for (int k = 0; k < net.numHidden1; k++)

         /*
         * Evaluate the second hidden layer (n = 2)
         * Iterate through each neuron in the hidden activation layer
         */
         for (int j = 0; j < net.numHidden2; j++)
         {
            //Declare Θj
            double Θj = 0.0;

            //Loop through hidden activations from previous layer (n=1)
            for (int k = 0; k < net.numHidden1; k++)
            {
               //Sum the dot products into the value of the activation
               Θj += net.activations[1][k] * net.weights[1][k][j];
            } //for (int k = 0; k < net.numHidden1; k++)

            //Then do the sigmoid
            net.activations[2][j] = sigmoid(Θj);
         } //for (int j = 0; j < net.numHidden2; j++)

         //Now calculate output(s), loop through number of outputs
         for (int i = 0; i < net.numOutputs; i++)
         {
            //Declare Θi
            double Θi = 0.0;

            for (int j = 0; j < net.numHidden2; j++)
            {
               //Sum the dot products into the value of the activation
               Θi += net.activations[2][j] * net.weights[2][j][i];
            } //for (int j = 0; j < net.numHidden2; j++)

            //Then do the sigmoid
            net.activations[3][i] = sigmoid(Θi);
         } //for (int i = 0; i < net.numOutputs; i++)
         
         //Calculate error
         double thisError = 0.0;
         for (int i = 0; i < net.numOutputs; i++)
         {
            //Add error for this run to total error
            thisError += calculateError(net.activations[net.numLayers-1][i], net.expectedOutputValues[a][i]);
            totalError += calculateError(net.activations[net.numLayers-1][i], net.expectedOutputValues[a][i]);
         } //for (int i = 0; i < net.numOutputs; i++)

         //Print truth table if required
         if (printTable)
         {
            //Print out the input activations
            for (int k = 0; k < net.numInputs; k++)
            {
               System.out.print(net.activations[0][k] + " ");
            } //for (int k = 0; k < net.numInputs; k++)

            //Get a bit more space
            System.out.print("  ");

            //Print out the expected outputs
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(net.expectedOutputValues[a][i] + " ");
            } //for (int i = 0; i < net.numOutputs; i++)

            //Get a bit more space
            System.out.print("  ");

            //Print out the actual outputs - hardcoded for 4 layer network
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(net.activations[3][i] + "\t");
            } //for (int i = 0; i < net.numOutputs; i++)

            //Now go to a new line
            System.out.println(" ");
         } //if (printTable)
      
         //Truth table but with error
         if (printComplete)
         {
            //Print out the input activations
            for (int k = 0; k < net.numInputs; k++)
            {
               System.out.print(net.activations[0][k] + " ");
            } //for (int k = 0; k < net.numInputs; k++)
         
            //Get a bit more space
            System.out.print("  ");
         
            //Print out the expected outputs
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(net.expectedOutputValues[a][i] + " ");
            } //for (int i = 0; i < net.numOutputs; i++)
         
            //Get a bit more space
            System.out.print("  ");
         
            //Print out the actual outputs - hardcoded for 4 layer network
            for (int i = 0; i < net.numOutputs; i++)
            {
               System.out.print(net.activations[3][i] + "\t");
            } //for (int i = 0; i < net.numOutputs; i++)
         
            //Print error
            System.out.print(thisError);

            //Now go to a new line
            System.out.println(" ");
         } //if (printComplete)

      } //for (int a = 0; a < net.possibleInputValues.length; a++)

      if (printComplete)
      {
         System.out.println("Total Error: " + totalError);
      }

      //saveWeights(net, net.weightFileName);
      return totalError;
   } //private static double runNetwork(NeuralNetwork net, boolean out, boolean table)

   /**
    * Run the forward prop part of the network for training
    * @param net the neural network used for the forward prop
    * @param error the current error of the network
    * @param whichCase the current single set case being trained
    * @return the single set error of the network
    */
   private static double runForTraining(NeuralNetwork net, double error, int whichCase)
   {

      //Calculate jk, Θj, ψi. For each output activation
      for (int i = 0; i < net.numOutputs; i++)
      {
         //Zero Θi before calculating it
         double Θi = 0.0;
         //For each hidden activation on layer 3 (n=2)
         for (int j = 0; j < net.numHidden2; j++)
         {
            //Zero Θj
            net.Θj[j] = 0.0;
            //For each hidden activation on layer 3 (n=1)
            for (int k = 0; k < net.numHidden1; k++)
            {
               //Zero Θk
               net.Θk[k] = 0.0;
               //For each input activation
               for (int m = 0; m < net.numInputs; m++)
               {
                  net.Θk[k] += net.am[m] * net.weights[0][m][k];
               } //for (int m = 0; m < net.numInputs; m++)
               //Calculate and store ak and Θj
               net.ak[k] = sigmoid(net.Θk[k]);
               net.Θj[j] += net.ak[k] * net.weights[1][k][j];
            } //for (int k = 0; k < net.numHidden1; k++)
            //Calculate and store aj
            net.aj[j] = sigmoid(net.Θj[j]);
            Θi += net.aj[j] * net.weights[2][j][i];
         } //for (int j = 0; j < net.numHidden2; j++)

         net.ai[i] = sigmoid(Θi);
         //(net.Ti[i] - Fi) is the difference between expected and actual output
         net.ψi[i] = (net.Ti[i] - net.ai[i]) * sigmoidDeriv(Θi);
         //Sum up single set error
         net.singleSetError += calculateError(sigmoid(Θi), net.Ti[i]);
      } //for (int i = 0; i < net.numOutputs; i++)

      //If all single set errors have been calculated, then new total error of the network has been calculated
      if (whichCase == net.expectedOutputValues.length-1)
      {
         error = net.singleSetError;
         net.singleSetError = 0.0;
         return error;
      } //if (whichCase == net.expectedOutputValues.length-1)

      //Otherwise new total error has not been calculated yet and return previous error
      else
      {
         return error;
      } //else
   } //private static double runForTraining(NeuralNetwork net, double error, int whichCase)

   /**
    * Train the neural network using gradient descent with backpropagation implemented for efficiency
    * @param net the neural network to be trained
    * @param saveFrequency how often the weights will be saved (every saveFrequency cycles)
    */
   private static void trainNetwork(NeuralNetwork net, int saveFrequency)
   {     

      double start = System.currentTimeMillis();

      //Error calculated by running network - set to 1 now but just temporary until network is run
      double error = 1.0;
      //Number of cycles
      int cycles = 0;
      //To store the single set error

      //Loop through training until a end condition is met
      while (cycles < net.cyclesMax && error > net.minError)
      {
         //Cycle what is expected from the 4 output cases
         net.Ti = net.expectedOutputValues[cycles % net.expectedOutputValues.length];
         net.am = net.possibleInputValues[cycles % net.expectedOutputValues.length];

         //Fill forward prop arrays, calculate error (is only adjusted once all single set errors are calculated)
         error = runForTraining(net, error, cycles % net.expectedOutputValues.length);


         //Declare Ωj
         double Ωj = 0.0;
         //For each hidden activation on 3rd layer (n=2)
         for (int j = 0; j < net.numHidden2; j++)
         {
            //Zero Ωj
            Ωj = 0.0;
            //For each output activation
            for (int i = 0; i < net.numOutputs; i++)
            {
               Ωj += net.ψi[i] * net.weights[2][j][i];
               //Update w2xx weights
               net.weights[2][j][i] += net.λ * net.aj[j] * net.ψi[i];
            } //for (int i = 0; i < net.numOutputs; i++)
            net.Ψj[j] = Ωj * sigmoidDeriv(net.Θj[j]);
         } //for (int j = 0; j < net.numHidden2; j++)

         //Declare Ωk 
         double Ωk = 0.0;
         //For each hidden activation on 2nd layer (n=1)
         for (int k = 0; k < net.numHidden1; k++)
         {
            //Zero Ωk
            Ωk = 0.0;
            //For each hidden activation on 3rd layer (n=2)
            for (int j = 0; j < net.numHidden2; j++)
            {
               Ωk += net.Ψj[j] * net.weights[1][k][j];
               net.weights[1][k][j] += net.λ * net.ak[k] * net.Ψj[j];
            } //for (int j = 0; j < net.numHidden2; j++)

            //For each input activation
            for (int m = 0; m < net.numInputs; m++)
            {
               net.weights[0][m][k] += net.λ * net.am[m] * Ωk * sigmoidDeriv(net.Θk[k]);
            } //for (int m = 0; m < net.numInputs; m++)
         } //for (int k = 0; k < net.numHidden1; k++)
         

         //Save weights every saveFrequency cycles
         if (cycles % saveFrequency == 0)
         {
            saveWeights(net, net.weightFileName);
         }
         
         //Increment # of cycles
         cycles++;
      } //while (cycles < cyclesMax && Error > minError)

      //End timer
      double timeTaken = System.currentTimeMillis() - start;

      //Get white space
      System.out.println();
      System.out.println();
      //Print why it stopped
      if (cycles >= net.cyclesMax)
      {
         System.out.println("Hit maximum number of loops.");
      } //if (cycles >= net.cyclesMax)
      else
      {
         System.out.println("Error was smaller than minError.");
      } //else

      //Print config and rand range
      System.out.println("Config: " + net.numInputs + " " + net.numHidden1 + " " + net.numHidden2 + " " + net.numOutputs);
      System.out.println("Rand range: " + net.minRand + " - " + net.maxRand);

      //Print N max, Emin, and lambda
      System.out.println("N max was: " + net.cyclesMax);
      System.out.println("Min Error was " + net.minError);
      System.out.println("λ was: " + net.λ);

      //Print Error then # of iteration, using runNetwork to get total error as the error used to stop is almost but not quite the same
      System.out.println("Error was: " + runNetwork(net, false, false));
      System.out.println("# of iterations: " + cycles);

      //Now print truth table
      System.out.println("Truth Table");
      runNetwork(net, false, true);

      //Print time taken
      timeTaken /= 1000;
      System.out.println();
      if (timeTaken > 60)
      {
         System.out.println("Time Taken: " + timeTaken/60 + "m " + timeTaken%60 + "s");
      } //if (timeTaken > 60)
      else
      {
         System.out.println("Time Taken: " + timeTaken + "s");
      }

      //Following whitespace
      System.out.println();
      System.out.println();

      //Save weights
      saveWeights(net, net.weightFileName);

   } //private static void trainNetwork()

   /**
    * Create a new network with many different specifications and set up the truth table (currently latter is hardcoded)
    * @param numInputs the number of input activations
    * @param numHidden1 the number of hidden activations on layer n=1
    * @param numHidden2 the number of hidden activations on layer n=2
    * @param numOutputs the number of output activations
    * @param numLayers the number of layers (must be 3 for now)
    * @param lambda the learning factor
    * @param weightFileName the name of the file where weights are saved/loaded
    * @param trainOrRun true if training false if running
    * @param cyclesMax max number of cycles while training
    * @param minError the minimum error at which training stops
    * @param minRand lower bound of random generation of weights
    * @param maxRand upper bound of random generations of weights
    * @param loadWeights whether to load weights or not
    * @param saveFrequency how often weights will be saved while training
    * @return a new neural network according to all of the parameters
    */
   private static NeuralNetwork createNetwork(int numInputs, int numHidden1, int numHidden2, int numOutputs, int numLayers, double lambda,
                                             String weightFileName, boolean trainOrRun, int cyclesMax, double minError,
                                             double minRand, double maxRand, boolean loadWeights, int saveFrequency)
   {
      NeuralNetwork net = new NeuralNetwork(numInputs, numHidden1, numHidden2, numOutputs, numLayers, lambda, weightFileName, trainOrRun,
                                             cyclesMax, minError, minRand, maxRand, saveFrequency);
 
      /*
      * Set up AND, OR, XOR (2 inputs 1 output), AndOrXor (2 inputs 3 outputs), 
      * ABCTester1 (3 inputs 4 outputs), or ABCTester2 (4 inputs 3 outputs)
      * Testers are on single line comments to make it easier to change between tests
      */

      //setupAND(net);
      //setupOR(net);
      //setupXOR(net);
      setupAndOrXor(net);
      //setupABCTester1(net);
      //setupABCTester2(net);
 
      //Load weights if told to, otherwise randomize weights
      if (loadWeights)
      {
         loadWeights(net.weightFileName, net);
      } //if (loadWeights)
      else
      {
         setRandomWeights(net, minRand, maxRand);
      } //else
 
    return net;
   } //private static NeuralNetwork createNetwork( lots of params )

   /**
    * Create and set up an instance of NeuralNetwork to be run or trained
    * @param args the arguments passed to (and ignored by) the main method
    */
   public static void main(String[] args) throws IOException
   {
      NeuralNetwork net = loadFromControl("control");

      //Either train or run the network based on the value of trainOrRun
      if (net.trainOrRun)
      {
         trainNetwork(net, net.saveFrequency);
      } //if (net.trainOrRun)
      else
      {
         runNetwork(net, true, false);
      } //else
   } //public static void main(String[] args) throws IOException
} //public class NeuralNetwork